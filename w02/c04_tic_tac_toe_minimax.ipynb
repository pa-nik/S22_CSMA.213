{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I love Tic-Tac-Toe. Besides brining back fond childhood memories, it offers a simple playground for a noob like me to learn more about Computer Science, Algorithms and AI. In this blog post , I will use the Mini-Max algorithm to solve the game of Tic Tac Toe.\n",
    "\n",
    "To solve the game means, we will be able to discover a strategy that ties the game against an optimal opponent and wins against any non-optimal opponent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are from Mars, and do not know how the game works, here are the rules courtesy of Wikipedia\n",
    "\n",
    "> \"Tic-tac-toe (American English), noughts and crosses (Commonwealth English and British English), or Xs and Os/“X’y O’sies” (Ireland), is a paper-and-pencil game for two players, X and O, who take turns marking the spaces in a 3×3 grid. The player who succeeds in placing three of their marks in a diagonal, horizontal, or vertical row is the winner. \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The  Minimax Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are already plenty of great resources to learn about the minimax algorithm like this [one](https://towardsdatascience.com/understanding-the-minimax-algorithm-726582e4f2c6) which I will liberally borrow from. I only briefly explain the algorithm here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mini-Max algorithm is perfect for 2-player (X vs Y) games like Tic-Tac-Toe where player X is trying to maximize his chances of winning while player Y is trying to minimize X's chances of winning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a small imaginary game where each player can make one of two moves (Left or Right). Player X moves first followed by player Y at which point the score of the game is known. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](minimax_mine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of the game ranges from 1-4. Player X wants to maximize this score while player Y tries to minimize it.To determine what is the optimal action player X should take , we should work backward from the end of the game.\n",
    "\n",
    "A,B,C,D,E,F and G are various states of the game where the latter 4 are terminal states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When making Move 2, Player Y can be in states B or C.\n",
    "\n",
    "In State B, Player Y can choose **L** to yield a score of 4 or **R** to yield score of E. Given, he wants to minimze the overall score , he will choose **R**.\n",
    "\n",
    "Similarly in State C, Player Y will choose **R** to minimze overall score. \n",
    "\n",
    "The value of States B and C are now 3 and 1 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first move, Player X is in state A. He can choose **L** which lands him in state B with a score of 3 or  choose **R** which lands him in state C with a score of 1.\n",
    "\n",
    "Given he wants to maximize the score, he chooses **L**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests an algorithm to choose the optimal move from any given state for a maximizing player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any given state, enumerate the possible child states. Now determine the value of these child states by invoking the minimizing player i.e. Ask the miniming player what he would do in each of these states and return the value he gets. Choose the action that leads to the highest value state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for for a minimizing player, enumerate the child states and determine the value of each state by invoking the maximizing player. Choose the action that leads to the lowest value state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If at any stage, the child state is a terminal state, the value of the terminal state is simply returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use code to solve the simple toy problem above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = {'a':['b','c'],'b':['d','e'],'c':['f','g']} #mapping from state to child states\n",
    "value = {'d':4,'e':3,'f':2,'g':1} # value of terminal states\n",
    "action = {'d':'L','e':'R','f':'L','g':'R','b':'L','c':'R'} # mapping from state to the action that produces that state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also keep a cache of the optimal next state for both maximizing and minimizing players, to make the computation a little faster. This hardly matters for this toy problem but can help for larger problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_optimal_next_states = {}\n",
    "min_optimal_next_states = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_children(state):\n",
    "    \"Function to produce children of a state\"\n",
    "    return children.get(state,None)\n",
    "\n",
    "def is_terminal(state):\n",
    "    \"Function to check if a state is terminal and return value of the state\"\n",
    "    if state in children:\n",
    "        return False,0\n",
    "    return True,value[state]\n",
    "\n",
    "def get_action(next_state,current_state=None): \n",
    "    \"Function to determine action that moves from current state to next state\"\n",
    "    #current state is redundant for this example as there is only one way to get to a state\n",
    "    \"Function to return action that moves player from current state to next state\"\n",
    "    return action[next_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def maximize(state):\n",
    "    \n",
    "    if state in max_optimal_next_states:\n",
    "        return max_optimal_next_states[state]\n",
    "    \n",
    "    terminal_status,reward = is_terminal(state)\n",
    "    if terminal_status:\n",
    "        return state,reward # No further state so return same state\n",
    "    \n",
    "    max_state, max_score = None,-np.Inf\n",
    "    max_states = []\n",
    "    children = produce_children(state)\n",
    "    for child in children:\n",
    "        _,score = minimize(child)\n",
    "        if score > max_score:\n",
    "            max_state,max_score = child,score\n",
    "            max_states = [max_state]\n",
    "        elif score == max_score: \n",
    "            max_states.append(child)\n",
    "            \n",
    "    # If multiple actions are optimal, break ties randomly\n",
    "    max_state = random.choice(max_states)\n",
    "    max_optimal_next_states[state] = (max_state,max_score)\n",
    "    \n",
    "    return max_state,max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(state):\n",
    "    \n",
    "    if state in min_optimal_next_states:\n",
    "        return min_optimal_next_states[state]\n",
    "    \n",
    "    terminal_status,reward = is_terminal(state)\n",
    "    if terminal_status:\n",
    "        return state,reward # No further state so return same state\n",
    "    \n",
    "    min_state, min_score = None,np.Inf\n",
    "    min_states = []\n",
    "    children = produce_children(state)\n",
    "    for child in children:\n",
    "        _,score = maximize(child)\n",
    "        if score < min_score:\n",
    "            min_state,min_score = child,score\n",
    "            min_states = [min_state]\n",
    "        elif score == min_score: \n",
    "            min_states.append(child)\n",
    "    \n",
    "    min_state = random.choice(min_states)\n",
    "    min_optimal_next_states[state] =  (min_state,min_score)\n",
    "    \n",
    "    return min_state,min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_decision(state,player = 'Maximizer'):\n",
    "    if player == 'Maximizer':\n",
    "        max_state,_ = maximize(state)\n",
    "        return get_action(max_state,state)\n",
    "    else:\n",
    "        min_state,_ = minimize(state)\n",
    "        return get_action(min_state,state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us confirm this returns the expected decisions in the image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_decision('a',player = 'Maximizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_decision('b',player = 'Minimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_decision('c',player = 'Minimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if the roles were reverse with Player X being a minimizer and Player Y being a maximizer. We expect the decisions to flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_decision('a',player = 'Minimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_decision('b',player = 'Maximizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_decision('c',player = 'Maximizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax in Limited Tic Tac Toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toy problem above can be easily mapped to a limited tic-tac-toe game as shown in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](minimax_ttt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, of the three possible moves available to player X in the starting state, the move to place 'X' in the centre square is the only action that leads to a winning outcome. This can be figured out by recursively applying the minimax algorithm as illustrated above.\n",
    "\n",
    "Note that Player X makes Move 1, Player Y makes Move 2 and Player X makes Move 3. This mini-game can end as early as after Move 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving TicTacToe with Minimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us denote player 'X' who plays first using 1 and player 'O' who plays second using 2. An empty square will be represented with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_to_b = {0:'__',1:'X',2:'O'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will denote the state of a game using a tuple of length 9.For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (1,0,0,2,0,0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_board(state):\n",
    "    \"Function to convert a a state(tuple) to a board(numpy array)\"\n",
    "    board = np.array([s_to_b[position] for position in state])\n",
    "    return board.reshape(3,3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state can be converted to a board using the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_board((1,0,0,2,0,0,0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A player wins if he or she gets a sequence of 'X's or 'O's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_player_wins = (1,1,1)\n",
    "min_player_wins = (2,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do is redefine the functions `is_terminal` , `produce_children` and `get_action` for the new tic-tac-toe problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A terminal state is reached if one of the players wins or if the board is fully occupied in which case the game is tied.<br>\n",
    "We will set the score of the game as follows: <br>\n",
    "X wins: + 10 <br>\n",
    "O wins: -10 <br>\n",
    "Draw: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(state):\n",
    "    \n",
    "    if  state[slice(0,3)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(0,3)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state[slice(3,6)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(3,6)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state[slice(6,9)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(6,9)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state[slice(0,7,3)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(0,7,3)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state[slice(1,8,3)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(1,8,3)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state[slice(2,9,3)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(2,9,3)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state[slice(0,9,4)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(0,9,4)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state[slice(2,7,2)] == max_player_wins:\n",
    "        return True,10\n",
    "    elif state[slice(2,7,2)] == min_player_wins:\n",
    "        return True,-10\n",
    "    elif state.count(0) == 0:\n",
    "        return True,0\n",
    "    else:\n",
    "        return False,0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function to produce the next set of possible states given a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def produce_children(state):\n",
    "    l = list(state)\n",
    "    children = []\n",
    "    vacant_slots = [i for i,v in enumerate(state) if v == 0]\n",
    "    if state.count(0) % 2 == 1: #If number of vacant spaces is odd , then it is max_player's turn\n",
    "        for slot in vacant_slots:\n",
    "            child = deepcopy(l)\n",
    "            child[slot] = 1\n",
    "            children.append(tuple(child))\n",
    "    else: #if number of vacant spaces is even then it is min_player's turn.\n",
    "        for slot in vacant_slots:\n",
    "            child = deepcopy(l)\n",
    "            child[slot] = 2\n",
    "            children.append(tuple(child))\n",
    "    \n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = produce_children(state)\n",
    "children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These correspond to the following states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in children:\n",
    "    print(state_to_board(child),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define a function to return the action  that leads from the current state to the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(tuple1,tuple2):\n",
    "    \"Helper function to get the index where first difference between two tuples is observed\"\n",
    "    assert len(tuple1) == len(tuple2)\n",
    "    for i,value in enumerate(tuple1):\n",
    "        if value != tuple2[i]:\n",
    "            return i\n",
    "    return None\n",
    "    \n",
    "def get_action(next_state,current_state):\n",
    "    return difference(next_state,current_state),next_state\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate whether we can solve the mini tic-tac-toe problem above with the tools at hand.The starting state of the game is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (1,2,1,0,0,2,0,2,1)\n",
    "state_to_board(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_action,optimal_next_state = optimal_decision(state,player = 'Maximizer')\n",
    "optimal_action,state_to_board(optimal_next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected , the algorithm determines the optimal action for player 'X' is to occupy the central square in the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider one more path in the game where player X plays a non-optimal move resulting in the following state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (1,2,1,1,0,2,0,2,1)\n",
    "state_to_board(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal state of the minimizing player is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_action,optimal_next_state = optimal_decision(state,player = 'Minimizer')\n",
    "optimal_action,state_to_board(optimal_next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimizing player also picks the optimal action as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will analyze the following games\n",
    "\n",
    "1) Random **X** vs Random **O** <br>\n",
    "2) Optimal **X** vs Random **O** <br> \n",
    "3) Random **X** vs Optimal **O** <br>\n",
    "4) Optimal **X** vs Optimal **O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function represents a random player who chooses an available slot at random. The maximizer is player **X** while the minimizer is player **O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_decision(state,player = 'Maximizer'):\n",
    "    vacant_slots = [i for i,v in enumerate(state) if v == 0]\n",
    "    action = random.choice(vacant_slots)\n",
    "    state_as_list = list(state)\n",
    "    #Update state\n",
    "    if player == 'Maximizer':\n",
    "        state_as_list[action] = 1\n",
    "    else:\n",
    "        state_as_list[action] = 2\n",
    "        \n",
    "    return action,tuple(state_as_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we wil define a function to play N games and record the results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_games(n_games:int,X_strategy,O_strategy):\n",
    "    '''\n",
    "    n_games: Number of games to be player\n",
    "    X_strategy: function describing decision making strategy for player X\n",
    "    O_strategy: function describing decision making strategy for player Y\n",
    "    '''\n",
    "    win_stats = defaultdict(int)\n",
    "    #Dictionary for holding no of wins for games started with a particual move\n",
    "    move_wins_X = defaultdict(int)\n",
    "    move_wins_O = defaultdict(int)\n",
    "    #Dictionary for holding no of games started with a particual move\n",
    "    move_X = defaultdict(lambda:-1)\n",
    "    move_O = defaultdict(lambda:-1)\n",
    "    \n",
    "    for i in tqdm(range(n_games)):\n",
    "        random.seed(i)\n",
    "        state = (0,0,0,0,0,0,0,0,0)\n",
    "        terminal_status = False\n",
    "       \n",
    "        first_move_flag_X = True # Flag identifying first move of player X\n",
    "        first_move_flag_O = True # Flag identifying first move of player O\n",
    "        \n",
    "        \n",
    "        while not terminal_status:\n",
    "            #Player X plays;  \n",
    "            player_x_action,next_state = X_strategy(state,player='Maximizer')\n",
    "            terminal_status,score = is_terminal(next_state)\n",
    "            \n",
    "            if first_move_flag_X:\n",
    "                first_move_X = player_x_action\n",
    "                move_X[first_move_X] += 1\n",
    "                first_move_flag_X = False\n",
    "            \n",
    "            #If player X plays last move\n",
    "            if terminal_status:\n",
    "                if score == 10: #player X wins\n",
    "                    win_stats['X_win'] +=1\n",
    "                    move_wins_X[first_move_X] += 1 #record player's first move\n",
    "                else:\n",
    "                    win_stats['Draw'] += 1\n",
    "                break\n",
    "            \n",
    "            state = next_state\n",
    "            #Player O plays next\n",
    "            \n",
    "            player_o_action,next_state = O_strategy(state,player='Minimizer')\n",
    "            terminal_status,score = is_terminal(next_state)\n",
    "            \n",
    "            if first_move_flag_O:\n",
    "                first_move_O = player_o_action\n",
    "                move_O[first_move_O] += 1\n",
    "                first_move_flag_O = False\n",
    "            \n",
    "            \n",
    "            #If player O plays last move\n",
    "            if terminal_status:\n",
    "                if score == -10: #player O wins\n",
    "                    win_stats['O_win'] +=1\n",
    "                    move_wins_O[first_move_O] += 1 #record player's first move\n",
    "                else:\n",
    "                    win_stats['Draw'] += 1\n",
    "                break\n",
    "            \n",
    "            state = next_state    \n",
    "        \n",
    "    return win_stats,move_wins_X,move_wins_O,move_X,move_O\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a helper function to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "def plot_results(results):\n",
    "    win_stats,move_wins_X,move_wins_O,move_X,move_O = results\n",
    "    win_stats_df = pd.DataFrame({'Category':list(win_stats.keys()),'Count':list(win_stats.values())})\n",
    "    move_X_win_rate = {i:move_wins_X[i]/move_X[i]  for i in range(9)}\n",
    "    move_O_win_rate = {i:move_wins_O[i]/move_O[i]  for i in range(9)}\n",
    "    \n",
    "    \n",
    "    move_X_win_rate_array = np.array([move_X_win_rate[x] for x in range(9)]).reshape(3,3)\n",
    "    move_O_win_rate_array = np.array([move_O_win_rate[x] for x in range(9)]).reshape(3,3)\n",
    "\n",
    "        \n",
    "    sns.set(font_scale=2)\n",
    "    fig, axs = plt.subplots(ncols=3,figsize=(30,10))\n",
    "    splot = sns.barplot(x=\"Category\",y=\"Count\",data=win_stats_df,ax=axs[0])\n",
    "    for p in splot.patches:\n",
    "        splot.annotate(format(p.get_height(), '.0f'), \n",
    "                       (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                       ha = 'center', va = 'center', \n",
    "                       xytext = (0, -12), \n",
    "                       textcoords = 'offset points')\n",
    "    splot.set_title('Distribution of Wins,Losses and Ties')\n",
    "    \n",
    "    sns.heatmap(move_X_win_rate_array,annot=True,ax = axs[1]).set_title('Player X:% of wins for first move')\n",
    "    sns.heatmap(move_O_win_rate_array,annot=True,ax = axs[2]).set_title('Player Y:% of wins for first move')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random X vs Random O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = play_games(1000,X_strategy=random_decision,O_strategy=random_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both players follow a random strategy, player X has a first mover advantage and wins the majority of the games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that given both players use random strategies: player X can play the first move in any of the squares without it affecting the win rate significantly.\n",
    "\n",
    "For player O on the other hand, playing the first move in the central or corner square results in a significantly higher win rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal X vs Random O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = play_games(1000,X_strategy=optimal_decision,O_strategy=random_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When player X uses the optimal minimax strategy,it wins almost all the games.\n",
    "\n",
    "It consistently picks the bottom right hand corner in the first move in every game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random X vs Optimal O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = play_games(1000,X_strategy=random_decision,O_strategy=optimal_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, O has a lower win rate given it does not have a fist movee advantage.\n",
    "\n",
    "The win rate is highest when Player O gets to occupy the central square in the first move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal X vs Optimal O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = play_games(100,X_strategy=optimal_decision,O_strategy=optimal_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both players play the optimal strategy, all games end in ties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
